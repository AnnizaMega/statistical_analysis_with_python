# -*- coding: utf-8 -*-
"""Statistical Analysis With Python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mMVyKMWMI9APyw8bBPt4LuuD2l7pX287

#Importing Library Smoking Dataset from UK For Chi Square Analysis
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#load dataset
data = pd.read_csv('/content/smoking.csv')

"""Survey data on smoking habits from the United Kingdom. The data set can be used for analyzing the demographic characteristics of smokers and types of tobacco consumed. A data frame with 1691 observations on the following 12 variables.

#Data Overview
"""

#check the dimension of the data
print(data.shape)

#return first 5 rows of the dataset
data.head()

"""Attributes Description
- Gender: Categorized into Female and Male.
- Age: Individual's age.
- Marital Status: Classifications include Divorced, Married, Separated, Single, and Widowed.
- Highest Qualification: Different levels such as A Levels, Degree, GCSE/CSE, GCSE/O Level, Higher/Sub Degree, No Qualification, ONC/BTEC, and Other/Sub Degree.
- Nationality: Options include British, English, Irish, Scottish, Welsh, Other, Refused, and Unknown.
- Ethnicity: Classifications comprise Asian, Black, Chinese, Mixed, White, and Refused Unknown.
- Gross Income: Income levels categorized as Under 2,600, 2,600 to 5,200, 5,200 to 10,400, 10,400 to 15,600, 15,600 to 20,800, 20,800 to 28,600, 28,600 to 36,400, Above 36,400, Refused, and Unknown.
- Region: Regions include London, Midlands & East Anglia, Scotland, South East, South West, The North, and Wales.
- Smoke: Smoking status categorized as No and Yes.
- Amount Weekends: Number of cigarettes smoked per day during weekends.
- Amount Weekdays: Number of cigarettes smoked per day during weekdays.
- Type: Type of cigarettes smoked categorized as Packets, Hand-Rolled, Both/Mainly Packets, and Both/Mainly Hand-Rolled.
"""

data.info()

"""#Data Visualization"""

# visualize the distribution of smoker and non smokers in the sample
smoking = data['smoke'].value_counts()
display(smoking)

figure, axes = plt.subplots(1,2, figsize=(15,5), gridspec_kw={'width_ratios':[1.2,1]})
axes[0].barh(y=smoking.index, width=smoking.values, color=['b','c'])
axes[0].set_xlabel('Frequency')
axes[0].grid(alpha=0.4)

for index, values in enumerate(smoking):
    axes[0].text(values+20, index, str(values), va='center')

axes[1].pie(smoking.values, labels=smoking.index, explode=[0.05,0.05], colors=['c','b'], autopct='%1.1f%%', pctdistance=0.5)

figure.suptitle('Distribution of Smoker vs Non Smokers', fontsize=15)
plt.tight_layout()
plt.show()

# visualization of the distribution of `age` in the sample data

display(data['age'].describe())

figure, axes = plt.subplots(1,2, figsize=(15,5), gridspec_kw={'width_ratios':[2,1]})
# visualization 1 - Histogram
sns.histplot(data=data, x=data['age'], ax=axes[0], color='c')
axes[0].grid(alpha=0.4)

# visualization 2 - Boxplot
sns.boxplot(data=data, y=data['age'], ax=axes[1], color='c')

figure.suptitle('Distribution of Age of the Sample Data', fontsize=15)
plt.tight_layout()
plt.show()

# visualize the distribution of different marital status in the sample
marital = data['marital_status'].value_counts()
display(marital)

figure, axes = plt.subplots(1,2, figsize=(15,5), gridspec_kw={'width_ratios':[1.2,1]})
axes[0].barh(y=marital.index, width=marital.values, color=['c','m','b','red','orange'])
axes[0].set_xlabel('Frequency')
axes[0].grid(alpha=0.4)

for index, values in enumerate(marital):
    axes[0].text(values+20, index, str(values), va='center')

axes[1].pie(marital.values, labels=marital.index, explode=[0.05,0.05,0,0,0], colors=['b','c','m','red','orange'], autopct='%1.1f%%', pctdistance=0.5)

figure.suptitle('Distribution of Samples by Different Marital Status', fontsize=15)
plt.tight_layout()
plt.show()

# visualize the distribution of different marital status in the sample
edu = data['highest_qualification'].value_counts()
display(edu)

figure, axes = plt.subplots(1,2, figsize=(15,6), gridspec_kw={'width_ratios':[1.2,1]})
axes[0].barh(y=edu.index, width=edu.values, color=['b','c','m','red','orange','g','lawngreen','mediumseagreen'])
axes[0].set_xlabel('Frequency')
axes[0].grid(alpha=0.4)

for index, values in enumerate(edu):
    axes[0].text(values+10, index, str(values), va='center')

axes[1].pie(edu.values, labels=edu.index, explode=[0.05,0.05,0,0,0,0,0,0], colors=['b','c','m','red','orange','g','lawngreen','mediumseagreen'], autopct='%1.1f%%', pctdistance=0.5)

figure.suptitle('Distribution of Samples by Different Education Levels', fontsize=15)
plt.tight_layout()
plt.show()

# visualize the distribution of different marital status in the sample
nat = data['nationality'].value_counts()
display(nat)

figure, axes = plt.subplots(1,2, figsize=(15,6), gridspec_kw={'width_ratios':[1.2,1]})
axes[0].barh(y=nat.index, width=nat.values, color=['b','c','m','red','orange','g','lawngreen','mediumseagreen'])
axes[0].set_xlabel('Frequency')
axes[0].grid(alpha=0.4)

for index, values in enumerate(nat):
    axes[0].text(values+10, index, str(values), va='center')

axes[1].pie(nat.values, labels=nat.index, explode=[0.05,0.05,0,0,0,0,0,0], colors=['b','c','m','red','orange','g','lawngreen','mediumseagreen'], autopct='%1.1f%%', pctdistance=0.5)

figure.suptitle('Distribution of Samples by Nationality', fontsize=15)
plt.tight_layout()
plt.show()

"""The difference between "nationality British" and "nationality English" is that "nationality British" encompasses all individuals who hold British citizenship, including people from England, Scotland, Wales, and Northern Ireland. Meanwhile, "nationality English" specifically refers to individuals who are from England. In other words, all English people are part of the British category, but not all British people are English. People from Scotland, Wales, and Northern Ireland are also included in the British category, but not in the English category.

#Chi square

##Question 1
Is there a significant association between gender and smoking status among a sample population?

Null Hypothesis (H0): There is no significant association between gender and smoking status.

Alternative Hypothesis (H1): There is a significant association between gender and smoking status.
"""

from scipy.stats import chi2_contingency

plt.figure()
sns.countplot(data=data, x=data['smoke'], hue=data['gender'])
plt.title('Distribution of Smoker vs Non-Smoker by Gender')
plt.grid(alpha=0.4)
plt.show()

contingency_table = pd.crosstab(data['gender'], data['smoke'])
res = chi2_contingency(contingency_table)

test_stat = round(res[0], 4)
test_pvalue = round(res[1], 4)

print("\nChi-square Test Statistics:")
print(f"Chi-square value: {test_stat}")
print(f"P-value: {test_pvalue}")

# check if the association is significant
alpha = 0.05
if test_pvalue < alpha:
    print("\nThere is a significant association between gender and smoking status.")
else:
    print("\nThere is no significant association between gender and smoking status.")

"""Based on the data collected, there appears to be no meaningful relationship between gender and smoking status within the sample population. This suggests that gender alone may not be a strong predictor of smoking behavior among individuals in this particular group. Other factors might play a more significant role in determining smoking status. Further investigation into additional variables could provide a more comprehensive understanding of the factors influencing smoking habits.

##Question 2
Is there a significant association between the highest education level and smoking status among the study population?

Null Hypothesis (H0): There is no significant association between the education level and smoking status in the population.

Alternative Hypothesis (H1): There is a significant association between the education level and smoking status in the population.
"""

plt.figure()
sns.countplot(data=data, x=data['smoke'], hue=data['highest_qualification'])
plt.title('Distribution of Smoker vs Non-Smoker by Education Level')
plt.xlabel('Smoking Status')
plt.grid(alpha=0.4)
plt.show()

contingency_table = pd.crosstab(data['highest_qualification'], data['smoke'])
res = chi2_contingency(contingency_table)

test_stat = round(res[0], 4)
test_pvalue = round(res[1], 4)

print("\nChi-square Test Statistics:")
print(f"Chi-square value: {test_stat}")
print(f"P-value: {test_pvalue}")

# check if the association is significant
alpha = 0.05
if test_pvalue < alpha:
    print("\nThere is a significant association between education level and smoking status.")
else:
    print("\nThere is no significant association between education level and smoking status.")

"""The summarized insight from the analysis is that there exists a significant association between the highest education level and smoking status among the study population. This suggests that individuals' educational attainment may play a role in determining their smoking habits. Higher education levels might be associated with different attitudes, knowledge, or access to resources related to smoking cessation or prevention. Understanding this association could inform targeted interventions or public health campaigns aimed at reducing smoking prevalence within specific educational demographics.

#Import Library Dataset For Linear regression
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

df = pd.read_csv('/content/Salary_dataset.csv')
df.head()

df.info()

"""#Regression Linear"""

X = df.YearsExperience.values.reshape(-1, 1)
y = df.Salary

model = LinearRegression().fit(X,y)

model.coef_

model.intercept_

model.coef_
model.intercept_
df['predict'] = model.predict(X)

df.head()

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_absolute_percentage_error

mean_absolute_error(y, model.predict(X))

mean_absolute_percentage_error(y, model.predict(X)) * 100

plt.scatter(df['YearsExperience'],df['Salary'])
plt.plot(df['YearsExperience'],df['predict'],c='red')
plt.show()

"""#Predicting with multiple variables"""

# Check if the 'predict' column exists before attempting to drop it
if 'predict' in df.columns:
    df.drop(columns='predict', inplace=True)
    print("Column 'predict' dropped successfully.")
else:
    print("Column 'predict' does not exist in the DataFrame.")

# Creating new dataframe to predict salaries
data=[[9],[10],[11],[12],[13],[14],[15],[16],[20]]
d=pd.DataFrame(data,columns=['YearsExperience'])
d

#predicting salary
from sklearn.linear_model import LinearRegression

# Assuming 'X' is your feature matrix and 'y' is your target variable
# Instantiate and train the regression model
reg = LinearRegression()
reg.fit(X, y)

# Now you can use the trained model to make predictions on your dataset 'd'
p = reg.predict(d)

# Add predicted salaries to the dataset
d['Predicted_Salary'] = p

# Display the dataset with predicted salaries
print(d)

"""#Import dataset for pearson"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

df = pd.read_csv('/content/WA_Fn-UseC_-Telco-Customer-Churn.csv')
df.head()

n_rows, n_columns = df.shape
print(f"Number of columns: {n_columns} columns\nNumber of rws: {n_rows} rows")

df.dtypes

total_charge = df["TotalCharges"]
missing = total_charge[~total_charge.str.replace(".", "").str.isdigit()]
print("Number of missing total charge: ", len(missing))
missing.head()

# Coverting the total charge column to numeric
df["TotalCharges"] = df["TotalCharges"].apply(pd.to_numeric, errors="coerce")

"""Total charge should be a float but it showing as object. We will convert it to float.

#descriptive analysis
"""

total_charge = df["TotalCharges"].astype(str)
missing = total_charge[~total_charge.str.replace(".", "").str.isdigit()]
print("Number of missing total charge: ", len(missing))
missing.head()

"""in the dataframe above, the total charge column has some missing values."""

# Coverting the total charge column to numeric
df["TotalCharges"] = df["TotalCharges"].apply(pd.to_numeric, errors="coerce")

#Displaying summary statistics of the numeric columns
styled_df = (
    df.describe()
    .drop("count", axis=0)
    .style.background_gradient(axis=0, cmap="magma")
    .set_properties(**{"text-align": "center"})
    .set_table_styles([{"selector": "th", "props": [("background-color", "k")]}])
    .set_caption("Summary Statistics")
)

styled_df

"""From the table above, total charge is showing as categorical which should not be so. It is supposed to be a numeric column. We will deal with it later."""

from tqdm import tqdm

numeric_columns = df.select_dtypes(include=["int64", "float64"]).columns

fig, axes = plt.subplots(2, 2, figsize=(7, 5))
axes = axes.flatten()
for i, column in enumerate(tqdm(numeric_columns)):
    ax = axes[i]
    sns.barplot(data=df, x="Churn", y=column, ax=ax, estimator=np.mean, palette=['blue', 'green'])
    ax.set_title(f"{column} vs Churn Label", fontsize=10)

    for k in ax.containers:
        ax.bar_label(
            k, fontsize=10, label_type="center", backgroundcolor="w", fmt="%.2f"
        )
plt.tight_layout()
plt.show()

"""Interpretation

- **Tenure Months:**
  - Customers who have not churned tend to have a longer average tenure of about 37.57 months, compared to churned customers whose average tenure is significantly lower at around 17.98 months. This suggests that longer tenure is associated with lower churn rates.

- **Monthly Charges:**
  - On average, customers who have churned tend to have slightly higher monthly charges of approximately $74.44, compared to non-churned customers whose average monthly charges are around $61.27. This indicates that higher monthly charges might contribute to customer churn.

- **Total Charges:**
  - Non-churned customers have notably higher average total charges of about $2,554.77, compared to churned customers whose average total charges are significantly lower at around $1,531.80. This suggests that customers with higher total charges are more likely to stay subscribed.

- **CLTV (Customer Lifetime Value):**
  - The average CLTV for non-churned customers is slightly higher at approximately $4,490.92, compared to churned customers whose average CLTV is around $4,149.41. This implies that customers with higher CLTV are more likely to continue their subscriptions without churning.

#Pearson's Correlation
"""

df.corr(method='pearson')

corr = df.corr(numeric_only=True)

mask = np.triu(np.ones_like(corr, dtype=bool))

plt.figure(figsize=(6, 3))
sns.heatmap(corr, mask=mask, annot=True, fmt=".2f", linecolor="c")
plt.title("Pearson's Correlation Matrix")
plt.show()

"""Interpretation of correlation coefficient

Correlation coefficients provide insights into the relationships between various attributes in the dataset. Here, I'll focus on a few noteworthy correlations:

1.Tenure Months and Total Charges (0.825): There is a strong positive correlation between tenure (number of months a customer has stayed with the company) and total charges. This suggests that customers who have been with the company for a longer time tend to accumulate higher total charges. It's an intuitive relationship as long-term customers are likely to pay more over time.

2.Tenure Months and Monthly Charges (0.248): Tenure months and monthly charges have a positive correlation, but it's relatively weaker. This indicates that, in general, longer-tenured customers tend to have slightly higher monthly charges. It's a subtle trend, suggesting that some long-term customers might choose higher-priced services.

3.Total Charges and CLTV (0.341): There's a positive correlation between total charges and Customer Lifetime Value (CLTV), indicating that customers who generate higher total charges are more valuable to the company in the long run. This correlation underscores the importance of retaining high-spending customers for business profitability.

These correlations provide a foundation for further analysis, such as identifying key factors influencing customer churn and understanding the drivers behind customer value and loyalty. Understanding these relationships can be valuable for decision-making and customer retention strategies.
"""